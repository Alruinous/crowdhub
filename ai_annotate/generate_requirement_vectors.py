"""
ä½¿ç”¨ DeepSeek API ä¸ºæ¯æ¡æ•°æ®ç”Ÿæˆä»»åŠ¡éœ€æ±‚å‘é‡
æ¯ä¸ªå‘é‡æœ‰ 22 ä¸ªç»´åº¦ï¼Œå¯¹åº”ä¸åŒçš„ç§‘æŠ€é¢†åŸŸï¼Œå–å€¼èŒƒå›´ 0-1
"""

import pandas as pd
import json
import os
from openai import OpenAI
from typing import Dict, List
import time
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# 22ä¸ªç§‘æŠ€é¢†åŸŸ
CATEGORIES = [
    "å¤©æ–‡åœ°ç†",
    "å†å²æ–‡æ˜",
    "å·¥ä¸šæŠ€æœ¯",
    "æ•°å­¦",
    "ç‰©ç†",
    "åŒ–å­¦",
    "ç¯å¢ƒç§‘å­¦",
    "èƒ½æºç§‘æŠ€",
    "å†›äº‹ç§‘æŠ€",
    "å»ºç­‘æ°´åˆ©",
    "äº¤é€šè¿è¾“",
    "å†œæ—ç‰§æ¸”",
    "èˆªç©ºèˆªå¤©èˆªæµ·",
    "å¥åº·ç®¡ç†",
    "ä¸´åºŠçŸ¥è¯†",
    "å®‰å…¨ç§‘å­¦",
    "ä¿¡æ¯æŠ€æœ¯",
    "ç”Ÿç‰©å­¦",
    "ææ–™ç§‘å­¦",
    "ç§‘å­¦å®¶",
    "ç§‘å­¦ç§‘å¹»",
    "å…¶ä»–",
]


def init_deepseek_client(api_key: str = None) -> OpenAI:
    """åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯"""
    if api_key is None:
        api_key = os.getenv("DEEPSEEK_API_KEY")
        if not api_key:
            raise ValueError("è¯·è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡æˆ–ä¼ å…¥ api_key å‚æ•°")
    
    return OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com"
    )


def generate_requirement_vectors_batch(client: OpenAI, rows_data: List[pd.Series]) -> List[Dict[str, float]]:
    """
    ä½¿ç”¨ DeepSeek API æ‰¹é‡ä¸ºå¤šæ¡æ•°æ®ç”Ÿæˆéœ€æ±‚å‘é‡
    
    å‚æ•°:
    - client: OpenAI å®¢æˆ·ç«¯
    - rows_data: æ•°æ®è¡Œåˆ—è¡¨
    
    è¿”å›:
    - requirement_vectors: éœ€æ±‚å‘é‡åˆ—è¡¨
    """
    batch_size = len(rows_data)
    
    # æ„å»ºæ‰¹é‡æ•°æ®æè¿°
    resources_info = []
    for idx, row in enumerate(rows_data, 1):
        resources_info.append(f"""èµ„æº {idx}ï¼š
- èµ„æºåç§°ï¼š{row.get('èµ„æºåç§°', 'N/A')}
- ç§‘æŠ€é¢†åŸŸï¼š{row.get('ç§‘æŠ€é¢†åŸŸ', 'N/A')}
- èµ„æºç±»å‹ï¼š{row.get('èµ„æºç±»å‹', 'N/A')}
- é€‚ç”¨å­¦æ®µï¼š{row.get('é€‚ç”¨å­¦æ®µ', 'N/A')}
- è¯¾ç¨‹ç±»å‹ï¼š{row.get('å¦‚ä½•è¯¾ç¨‹ç±»å‹(è¯¾ç¨‹/éè¯¾ç¨‹)', 'N/A')}""")
    
    resources_text = "\n\n".join(resources_info)
    
    # æ„å»ºæç¤ºè¯
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘æ•™èµ„æºåˆ†ç±»è¯„ä¼°ä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æä»¥ä¸‹ {batch_size} ä¸ªç§‘æ•™èµ„æºï¼Œä¸ºæ¯ä¸ªèµ„æºè¯„ä¼°å®Œæˆå…¶æ ‡æ³¨ä»»åŠ¡éœ€è¦å¯¹å„ç§‘æŠ€é¢†åŸŸçš„çŸ¥è¯†æŒæ¡ç¨‹åº¦ã€‚

{resources_text}

ã€22ä¸ªç§‘æŠ€é¢†åŸŸè¯´æ˜ã€‘
1. å¤©æ–‡åœ°ç† - å¤©æ–‡å­¦ã€åœ°çƒç§‘å­¦ã€åœ°ç†å­¦ã€åœ°è´¨å­¦ã€æ°´æ–‡å­¦ã€æµ·æ´‹ç§‘å­¦
2. å†å²æ–‡æ˜ - å†å²å­¦ã€è€ƒå¤å­¦ã€å“²å­¦ã€å®—æ•™å­¦ã€ç¤¾ä¼šå­¦ã€æ³•å­¦ç­‰äººæ–‡ç¤¾ç§‘
3. å·¥ä¸šæŠ€æœ¯ - å·¥ä¸šåŸºç¡€ã€çººç»‡ã€åŠ¨åŠ›ç”µå™¨ã€çŸ¿å±±ã€å†¶é‡‘ã€æœºæ¢°å·¥ç¨‹
4. æ•°å­¦ - æ•°å­¦
5. ç‰©ç† - ç‰©ç†å­¦ã€åŠ›å­¦
6. åŒ–å­¦ - åŒ–å­¦ã€åŒ–å­¦å·¥ç¨‹
7. ç¯å¢ƒç§‘å­¦ - ç¯å¢ƒç§‘å­¦æŠ€æœ¯ã€èµ„æºç§‘å­¦æŠ€æœ¯
8. èƒ½æºç§‘æŠ€ - èƒ½æºç§‘å­¦æŠ€æœ¯ã€æ ¸ç§‘å­¦æŠ€æœ¯
9. å†›äº‹ç§‘æŠ€ - å†›äº‹å­¦ã€å†›äº‹å·¥ç¨‹æŠ€æœ¯
10. å»ºç­‘æ°´åˆ© - æµ‹ç»˜ã€æ°´åˆ©å·¥ç¨‹ã€åœŸæœ¨å»ºç­‘å·¥ç¨‹
11. äº¤é€šè¿è¾“ - äº¤é€šè¿è¾“å·¥ç¨‹
12. å†œæ—ç‰§æ¸” - å†œå­¦ã€æ°´äº§å­¦ã€æ—å­¦ã€ç•œç‰§ã€å…½åŒ»
13. èˆªç©ºèˆªå¤©èˆªæµ· - èˆªç©ºèˆªå¤©ç§‘å­¦æŠ€æœ¯
14. å¥åº·ç®¡ç† - å¿ƒç†å­¦ã€é£Ÿå“ç§‘å­¦æŠ€æœ¯
15. ä¸´åºŠçŸ¥è¯† - åŸºç¡€åŒ»å­¦ã€è¯å­¦ã€ä¸­åŒ»å­¦ã€ä¸´åºŠåŒ»å­¦ã€é¢„é˜²åŒ»å­¦
16. å®‰å…¨ç§‘å­¦ - å®‰å…¨ç§‘å­¦æŠ€æœ¯
17. ä¿¡æ¯æŠ€æœ¯ - ä¿¡æ¯ç§‘å­¦ã€ç”µå­é€šä¿¡ã€è®¡ç®—æœºç§‘å­¦
18. ç”Ÿç‰©å­¦ - ç”Ÿç‰©å­¦
19. ææ–™ç§‘å­¦ - ææ–™ç§‘å­¦
20. ç§‘å­¦å®¶ - ç§‘å­¦å®¶äººç‰©ã€ç§‘å­¦å®¶æ•…äº‹
21. ç§‘å­¦ç§‘å¹» - ç§‘å¹»ä½œå“ã€ç§‘å¹»æ•…äº‹
22. å…¶ä»– - æ— æ³•å½’ç±»çš„å…¶ä»–å†…å®¹

ã€æ ¸å¿ƒè¯„åˆ†åŸåˆ™ - è¯·ä¸¥æ ¼æ‰§è¡Œï¼ã€‘
ç¬¬ä¸€æ­¥ï¼šä»”ç»†é˜…è¯»æ¯ä¸ªèµ„æºçš„å„ä¸ªå­—æ®µï¼Œå°¤å…¶æ˜¯"èµ„æºåç§°"ã€"ç§‘æŠ€é¢†åŸŸ"ã€"æ–‡ä»¶å"ç­‰
ç¬¬äºŒæ­¥ï¼šå°†è¿™äº›å­—æ®µä¸­çš„å†…å®¹ä¸ä¸Šè¿°22ä¸ªé¢†åŸŸè¿›è¡ŒåŒ¹é…
ç¬¬ä¸‰æ­¥ï¼šå¯¹åŒ¹é…ä¸Šçš„é¢†åŸŸç»™é«˜åˆ†ï¼ˆ0.8-0.9ï¼‰ï¼Œç›¸å…³é¢†åŸŸç»™ä¸­ç­‰åˆ†ï¼ˆ0.5-0.7ï¼‰ï¼Œä¸ç›¸å…³ç»™ä½åˆ†ï¼ˆ0.1-0.2ï¼‰

è¯„åˆ†è§„åˆ™ï¼š
- å¼ºç›¸å…³ï¼ˆèµ„æºçš„ç§‘æŠ€é¢†åŸŸå­—æ®µä¸­æ˜ç¡®æåˆ°ï¼‰ï¼š0.8-0.9
- ç›¸å…³ï¼ˆéœ€è¦è¯¥é¢†åŸŸèƒŒæ™¯çŸ¥è¯†ï¼‰ï¼š0.5-0.7
- å¼±ç›¸å…³ï¼ˆè½»å¾®å…³è”ï¼‰ï¼š0.3-0.4
- ä¸ç›¸å…³ï¼ˆå®Œå…¨æ— å…³ï¼‰ï¼š0.1-0.2

ã€ä¸¥æ ¼ç¦æ­¢ã€‘
âŒ æ‰€æœ‰èµ„æºç»™ç›¸åŒåˆ†æ•°ï¼ˆä¾‹å¦‚å…¨éƒ½æ˜¯"ç§‘å­¦å®¶":0.9, "å…¶ä»–":0.8ï¼‰
âŒ ç»™"ç§‘å­¦å®¶"ã€"å…¶ä»–"ç­‰é€šç”¨é¢†åŸŸè¿‡é«˜åˆ†æ•°ï¼ˆé™¤éèµ„æºç¡®å®æ˜¯å…³äºç§‘å­¦å®¶äººç‰©çš„ï¼‰

ã€è¾“å‡ºæ ¼å¼ã€‘
è¿”å›JSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªèµ„æºçš„è¯„åˆ†å¯¹è±¡ï¼š
[
  {{
    "å¤©æ–‡åœ°ç†": 0.8,
    "å†å²æ–‡æ˜": 0.3,
    ...ï¼ˆå…¨éƒ¨22ä¸ªé¢†åŸŸï¼‰
  }},
  ...ï¼ˆå…±{batch_size}ä¸ªå¯¹è±¡ï¼‰
]
ã€è¯„åˆ†ç¤ºä¾‹ã€‘
ç¤ºä¾‹1ï¼šèµ„æºåç§°"ä¸­å›½å¤©çœ¼ï¼šæç›®å…‰å¹´ä¹‹å¤–"ï¼Œç§‘æŠ€é¢†åŸŸ"ç§‘å­¦ä¸è‰ºæœ¯ï¼›ç§‘å­¦æ•™è‚²ç†è®º"
åˆ†æï¼š"ä¸­å›½å¤©çœ¼"æ˜¯å¤§å‹å°„ç”µæœ›è¿œé•œï¼Œå†…å®¹ä»¥å¤©æ–‡å­¦è§‚æµ‹ä¸ºæ ¸å¿ƒï¼Œæ¶‰åŠç‰©ç†åŸç†ä¸å·¥ç¨‹æŠ€æœ¯ï¼Œäººç‰©ä¸æ˜¯ä¸»çº¿ã€‚
è¯„åˆ†ï¼š{{"å¤©æ–‡åœ°ç†":0.9, "å†å²æ–‡æ˜":0.1, "å·¥ä¸šæŠ€æœ¯":0.3, "æ•°å­¦":0.4, "ç‰©ç†":0.6, "åŒ–å­¦":0.1, "ç¯å¢ƒç§‘å­¦":0.1, "èƒ½æºç§‘æŠ€":0.2, "å†›äº‹ç§‘æŠ€":0.0, "å»ºç­‘æ°´åˆ©":0.3, "äº¤é€šè¿è¾“":0.1, "å†œæ—ç‰§æ¸”":0.0, "èˆªç©ºèˆªå¤©èˆªæµ·":0.4, "å¥åº·ç®¡ç†":0.0, "ä¸´åºŠçŸ¥è¯†":0.0, "å®‰å…¨ç§‘å­¦":0.2, "ä¿¡æ¯æŠ€æœ¯":0.4, "ç”Ÿç‰©å­¦":0.0, "ææ–™ç§‘å­¦":0.3, "ç§‘å­¦å®¶":0.2, "ç§‘å­¦ç§‘å¹»":0.0, "å…¶ä»–":0.0}}

ç¤ºä¾‹2ï¼šèµ„æºåç§°"äººå·¥æ™ºèƒ½ï¼šæœªæ¥å·²æ¥"ï¼Œç§‘æŠ€é¢†åŸŸ"ç§‘å­¦ä¸è‰ºæœ¯ï¼›ç§‘å­¦æ•™è‚²ç†è®º"
åˆ†æï¼šå†…å®¹ä¸ºäººå·¥æ™ºèƒ½ç§‘æ™®ï¼Œé‡ç‚¹ä»‹ç»AIçš„æ¦‚å¿µä¸åº”ç”¨ï¼Œå±äºä¿¡æ¯æŠ€æœ¯é¢†åŸŸï¼Œæ•°å­¦ä¸ºé‡è¦æ”¯æ’‘ï¼Œéç§‘å¹»ä½œå“ã€‚
è¯„åˆ†ï¼š{{"å¤©æ–‡åœ°ç†":0.0, "å†å²æ–‡æ˜":0.1, "å·¥ä¸šæŠ€æœ¯":0.4, "æ•°å­¦":0.6, "ç‰©ç†":0.2, "åŒ–å­¦":0.0, "ç¯å¢ƒç§‘å­¦":0.0, "èƒ½æºç§‘æŠ€":0.1, "å†›äº‹ç§‘æŠ€":0.1, "å»ºç­‘æ°´åˆ©":0.0, "äº¤é€šè¿è¾“":0.1, "å†œæ—ç‰§æ¸”":0.0, "èˆªç©ºèˆªå¤©èˆªæµ·":0.1, "å¥åº·ç®¡ç†":0.1, "ä¸´åºŠçŸ¥è¯†":0.0, "å®‰å…¨ç§‘å­¦":0.3, "ä¿¡æ¯æŠ€æœ¯":0.9, "ç”Ÿç‰©å­¦":0.1, "ææ–™ç§‘å­¦":0.2, "ç§‘å­¦å®¶":0.1, "ç§‘å­¦ç§‘å¹»":0.3, "å…¶ä»–":0.0}}

ç¤ºä¾‹3ï¼šèµ„æºåç§°"å¤©çœ¼ä¹‹çˆ¶å—ä»ä¸œ"ï¼Œç§‘æŠ€é¢†åŸŸ"ç§‘å­¦ä¸è‰ºæœ¯ï¼›ç§‘å­¦æ•™è‚²ç†è®º"
åˆ†æï¼šå†…å®¹ä»¥ç§‘å­¦å®¶å—ä»ä¸œçš„ç§‘ç ”ç»å†ä¸ç²¾ç¥ä¸ºä¸»çº¿ï¼Œå¤©æ–‡é¢†åŸŸä½œä¸ºèƒŒæ™¯å‡ºç°ï¼Œäººç‰©å™äº‹ä¼˜å…ˆäºå…·ä½“å­¦ç§‘ã€‚
è¯„åˆ†ï¼š{{"å¤©æ–‡åœ°ç†":0.6, "å†å²æ–‡æ˜":0.3, "å·¥ä¸šæŠ€æœ¯":0.3, "æ•°å­¦":0.2, "ç‰©ç†":0.4, "åŒ–å­¦":0.0, "ç¯å¢ƒç§‘å­¦":0.0, "èƒ½æºç§‘æŠ€":0.1, "å†›äº‹ç§‘æŠ€":0.0, "å»ºç­‘æ°´åˆ©":0.2, "äº¤é€šè¿è¾“":0.0, "å†œæ—ç‰§æ¸”":0.0, "èˆªç©ºèˆªå¤©èˆªæµ·":0.2, "å¥åº·ç®¡ç†":0.0, "ä¸´åºŠçŸ¥è¯†":0.0, "å®‰å…¨ç§‘å­¦":0.1, "ä¿¡æ¯æŠ€æœ¯":0.2, "ç”Ÿç‰©å­¦":0.0, "ææ–™ç§‘å­¦":0.2, "ç§‘å­¦å®¶":0.9, "ç§‘å­¦ç§‘å¹»":0.0, "å…¶ä»–":0.0}}


åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦ä»»ä½•è§£é‡Šæ–‡å­—ã€‚"""

    # ====== è°ƒè¯•è¾“å‡ºï¼šæ‰“å°å®é™…æç¤ºè¯ ======
    # print(f"\n{'='*60}")
    # print(f"[è°ƒè¯•] å‘é€ç»™æ¨¡å‹çš„æç¤ºè¯ï¼ˆå‰800å­—ç¬¦ï¼‰:")
    # print(f"{'='*60}")
    # print(prompt[:800])
    # print("...(çœç•¥)")
    # print(f"{'='*60}\n")

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šä¸”ä¸¥æ ¼çš„ç§‘æ•™èµ„æºè¯„ä¼°ä¸“å®¶ã€‚ä½ å¿…é¡»ä»”ç»†é˜…è¯»æ¯ä¸ªèµ„æºçš„'ç§‘æŠ€é¢†åŸŸ'å­—æ®µï¼Œè¿™æ˜¯è¯„åˆ†çš„æ ¸å¿ƒä¾æ®ã€‚ä¸åŒçš„èµ„æºå¿…é¡»ç»™å‡ºå®Œå…¨ä¸åŒçš„è¯„åˆ†ã€‚ç»å¯¹ç¦æ­¢æ‰€æœ‰èµ„æºéƒ½ç»™ç›¸åŒçš„åˆ†æ•°ã€‚ç»å¯¹ç¦æ­¢å¿½è§†èµ„æºçš„ç§‘æŠ€é¢†åŸŸä¿¡æ¯è€Œç»™'ç§‘å­¦å®¶'æˆ–'å…¶ä»–'é«˜åˆ†ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.8,  # æé«˜æ¸©åº¦ä»¥å¢åŠ å·®å¼‚æ€§
            max_tokens=4000,  # å¢åŠ  token é™åˆ¶
        )
        
        # æå–å“åº”å†…å®¹
        content = response.choices[0].message.content.strip()
        
        # ====== è°ƒè¯•è¾“å‡ºï¼šæ‰“å°æ¨¡å‹å“åº” ======
        # print(f"\n{'='*60}")
        # print(f"[è°ƒè¯•] æ¨¡å‹è¿”å›çš„åŸå§‹å“åº”ï¼ˆå‰1000å­—ç¬¦ï¼‰:")
        # print(f"{'='*60}")
        # print(content[:1000])
        # if len(content) > 1000:
        #     print("...(çœç•¥)")
        # print(f"{'='*60}\n")
        
        # å»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
        if content.startswith("```json"):
            content = content[7:]
        if content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
        content = content.strip()
        
        # è§£æ JSON æ•°ç»„
        vectors = json.loads(content)
        
        # ====== è°ƒè¯•è¾“å‡ºï¼šéªŒè¯è§£æç»“æœ ======
        # print(f"\n{'='*60}")
        # print(f"[è°ƒè¯•] è§£æåçš„å‘é‡æ•°ç»„:")
        # print(f"  - æ•°ç»„é•¿åº¦: {len(vectors)}")
        # print(f"  - æœŸæœ›é•¿åº¦: {batch_size}")
        # if len(vectors) > 0:
        #     print(f"  - ç¬¬1ä¸ªå‘é‡ç¤ºä¾‹: {json.dumps(vectors[0], ensure_ascii=False)[:200]}...")
        #     if len(vectors) > 1:
        #         print(f"  - ç¬¬2ä¸ªå‘é‡ç¤ºä¾‹: {json.dumps(vectors[1], ensure_ascii=False)[:200]}...")
        # print(f"{'='*60}\n")
        
        # éªŒè¯æ•°ç»„é•¿åº¦
        if len(vectors) != batch_size:
            print(f"è­¦å‘Šï¼šè¿”å›çš„å‘é‡æ•°é‡ ({len(vectors)}) ä¸è¯·æ±‚æ•°é‡ ({batch_size}) ä¸åŒ¹é…")
            # è¡¥é½æˆ–æˆªæ–­
            while len(vectors) < batch_size:
                vectors.append({category: 0.5 for category in CATEGORIES})
            vectors = vectors[:batch_size]
        
        # éªŒè¯å’Œä¿®æ­£æ¯ä¸ªå‘é‡
        for i, vector in enumerate(vectors):
            for category in CATEGORIES:
                if category not in vector:
                    print(f"è­¦å‘Šï¼šèµ„æº {i+1} çš„é¢†åŸŸ '{category}' ç¼ºå¤±ï¼Œè®¾ç½®ä¸ºé»˜è®¤å€¼ 0.4")
                    vector[category] = 0.4
                else:
                    # ç¡®ä¿å€¼åœ¨ 0-1 èŒƒå›´å†…
                    vector[category] = max(0.0, min(1.0, float(vector[category])))
        
        return vectors
        
    except json.JSONDecodeError as e:
        print(f"JSON è§£æå¤±è´¥: {e}")
        print(f"åŸå§‹å“åº”: {content[:500]}...")  # åªæ‰“å°å‰500å­—ç¬¦
        # è¿”å›é»˜è®¤å‘é‡
        return [{category: 0.5 for category in CATEGORIES} for _ in range(batch_size)]
    except Exception as e:
        print(f"API è°ƒç”¨å¤±è´¥: {e}")
        # è¿”å›é»˜è®¤å‘é‡
        return [{category: 0.5 for category in CATEGORIES} for _ in range(batch_size)]


def process_excel_file(
    input_file: str,
    output_file: str,
    api_key: str = None,
    start_row: int = 0,
    max_rows: int = None,
    batch_size: int = 10,
    delay: float = 0.5
):
    """
    å¤„ç† Excel æ–‡ä»¶ï¼Œä¸ºæ¯æ¡æ•°æ®ç”Ÿæˆéœ€æ±‚å‘é‡ï¼ˆæ”¯æŒæ‰¹é‡å¤„ç†ï¼‰
    
    å‚æ•°:
    - input_file: è¾“å…¥çš„ Excel æ–‡ä»¶è·¯å¾„
    - output_file: è¾“å‡ºçš„ Excel æ–‡ä»¶è·¯å¾„
    - api_key: DeepSeek API Keyï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
    - start_row: èµ·å§‹è¡Œå·ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
    - max_rows: æœ€å¤šå¤„ç†å¤šå°‘è¡Œï¼ˆç”¨äºæµ‹è¯•ï¼‰
    - batch_size: æ¯æ¬¡æ‰¹é‡å¤„ç†çš„æ•°æ®æ¡æ•°ï¼ˆé»˜è®¤ 5ï¼‰
    - delay: æ¯æ¬¡ API è°ƒç”¨ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
    """
    print(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {input_file}")
    print(f"æ‰¹é‡å¤§å°: {batch_size} æ¡/æ¬¡")
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = init_deepseek_client(api_key)
    
    # è¯»å– Excel æ–‡ä»¶
    df = pd.read_excel(input_file)
    print(f"è¯»å–åˆ° {len(df)} æ¡æ•°æ®")
    
    # å¦‚æœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ï¼Œè¯»å–å·²æœ‰ç»“æœ
    if os.path.exists(output_file):
        print(f"å‘ç°å·²æœ‰è¾“å‡ºæ–‡ä»¶ï¼ŒåŠ è½½è¿›åº¦...")
        existing_df = pd.read_excel(output_file)
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœªå¤„ç†çš„è¡Œ
        if 'requirementVector' in existing_df.columns:
            start_row = existing_df['requirementVector'].notna().sum()
        print(f"ä»ç¬¬ {start_row + 1} è¡Œç»§ç»­å¤„ç†")
    
    # ç¡®å®šå¤„ç†èŒƒå›´
    end_row = len(df) if max_rows is None else min(start_row + max_rows, len(df))
    
    # æ·»åŠ éœ€æ±‚å‘é‡åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if 'requirementVector' not in df.columns:
        df['requirementVector'] = pd.Series(dtype='object')  # æ˜ç¡®æŒ‡å®šä¸ºobjectç±»å‹ï¼Œæ”¯æŒå­˜å‚¨JSONå­—ç¬¦ä¸²
    
    # æ‰¹é‡å¤„ç†
    total_batches = (end_row - start_row + batch_size - 1) // batch_size
    processed_count = 0
    
    for batch_idx in range(start_row, end_row, batch_size):
        batch_end = min(batch_idx + batch_size, end_row)
        current_batch_size = batch_end - batch_idx
        current_batch_num = (batch_idx - start_row) // batch_size + 1
        
        print(f"\n{'='*60}")
        print(f"æ‰¹æ¬¡ {current_batch_num}/{total_batches}: å¤„ç†ç¬¬ {batch_idx + 1}-{batch_end} æ¡æ•°æ®...")
        print(f"{'='*60}")
        
        # è·å–å½“å‰æ‰¹æ¬¡çš„æ•°æ®
        batch_rows = [df.iloc[i] for i in range(batch_idx, batch_end)]
        
        try:
            # æ‰¹é‡ç”Ÿæˆéœ€æ±‚å‘é‡
            vectors = generate_requirement_vectors_batch(client, batch_rows)
            
            # ä¿å­˜ç»“æœ
            for i, vector in enumerate(vectors):
                row_idx = batch_idx + i
                
                # ====== è°ƒè¯•è¾“å‡ºï¼šéªŒè¯å‘é‡åˆ†é… ======
                if i < 2:  # åªæ‰“å°å‰2ä¸ª
                    row = df.iloc[row_idx]
                
                df.at[row_idx, 'requirementVector'] = json.dumps(vector, ensure_ascii=False)
                
            processed_count += current_batch_size
            
            # æ¯ä¸ªæ‰¹æ¬¡åä¿å­˜ä¸€æ¬¡
            df.to_excel(output_file, index=False)
            print(f"\n  ğŸ’¾ å·²ä¿å­˜è¿›åº¦ ({processed_count}/{end_row - start_row} æ¡å®Œæˆ)")
            
            # å»¶è¿Ÿï¼Œé¿å…è¶…è¿‡ API é™åˆ¶
            if batch_end < end_row:
                print(f"  â³ ç­‰å¾… {delay} ç§’...")
                time.sleep(delay)
            
        except Exception as e:
            print(f"  âœ— æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤å‘é‡
            for i in range(current_batch_size):
                row_idx = batch_idx + i
                df.at[row_idx, 'requirementVector'] = json.dumps(
                    {cat: 0.5 for cat in CATEGORIES}, ensure_ascii=False
                )
    
    # æœ€ç»ˆä¿å­˜
    df.to_excel(output_file, index=False)
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_api_calls = total_batches
    time_saved = (end_row - start_row) - total_api_calls
    print(f"\n{'='*60}")
    print(f"âœ… å…¨éƒ¨å®Œæˆï¼")
    print(f"   - å¤„ç†æ•°æ®: {end_row - start_row} æ¡")
    print(f"   - API è°ƒç”¨: {total_api_calls} æ¬¡")
    print(f"   - ç»“æœæ–‡ä»¶: {output_file}")
    print(f"{'='*60}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¸ºç§‘æ•™èµ„æºæ•°æ®ç”Ÿæˆä»»åŠ¡éœ€æ±‚å‘é‡')
    parser.add_argument('input_file', help='è¾“å…¥çš„ Excel æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºçš„ Excel æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä¸º input_with_vectors.xlsxï¼‰')
    parser.add_argument('-k', '--api-key', help='DeepSeek API Keyï¼ˆé»˜è®¤ä»ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY è¯»å–ï¼‰')
    parser.add_argument('-s', '--start', type=int, default=0, help='èµ·å§‹è¡Œå·ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰')
    parser.add_argument('-m', '--max-rows', type=int, help='æœ€å¤šå¤„ç†å¤šå°‘è¡Œï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    parser.add_argument('-b', '--batch-size', type=int, default=10, help='æ¯æ¬¡æ‰¹é‡å¤„ç†çš„æ•°æ®æ¡æ•°ï¼ˆé»˜è®¤ 10ï¼‰')
    parser.add_argument('-d', '--delay', type=float, default=0.5, help='æ¯æ¬¡ API è°ƒç”¨ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰')
    
    args = parser.parse_args()
    
    # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
    if args.output is None:
        base_name = os.path.splitext(args.input_file)[0]
        output_file = f"{base_name}_with_vectors.xlsx"
    else:
        output_file = args.output
    
    # å¤„ç†æ–‡ä»¶
    process_excel_file(
        input_file=args.input_file,
        output_file=output_file,
        api_key=args.api_key,
        start_row=args.start,
        max_rows=args.max_rows,
        batch_size=args.batch_size,
        delay=args.delay
    )


if __name__ == "__main__":
    main()
